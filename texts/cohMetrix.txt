The vision of having a computer understand natural language has persisted for nearly half a century, but it has been challenged by the computational difficulty of simulating many of the processing components. The standard wisdom has been that it is particularly more difficult to implement the deeper and more global levels of comprehension than the shallow and more local levels. The deeper and global levels require semantic interpretation, the construction of mental models, text cohesion, pragmatics, rhetorical composition, and world knowledge (Lehnert & Ringle, 1982; Schank & Riesbeck, 1981). The computer is more reliable in managing the more shallow and local components, such as accessing words from electronic dictionaries, identifying misspelled words, and splitting up words into component syllables, basic meaning units (morphemes), or sound units (phonemes).Recent landmark progress across several disciplines has made it possible to explore computational measures of language and text comprehension that go beyond these surface components. These disciplines include computational linguistics (Allen, 1995; Jurafsky & Martin, 2000; Moore & Wiemer-Hastings, 2003), corpus linguistics (Biber, Conrad, & Reppen, 1998; Marcus, Santorini, & Marcinkiewicz, 1993), information extraction (DARPA, 1995; Lehnert, 1997; Pennebaker & Francis, 1999), information retrieval (Belew, 2002; Deerwester, Dumais, Furnas, Landauer, & Harshman, 1990; Graesser, Burger, et al., 2003; Robertson, 2001; Voorhees, 2001), and discourse processing (Graesser, Gernsbacher, & Goldman, 2003; Kintsch, 1998). As a consequence of these advances in scientific research and language technologies, we can go some distance in automating many of the deeper and global levels of text and language analysis.One such level of language analysis that presents particular computational challenges is called coherence or cohesion (Graesser, McNamara, & Louwerse, 2003; Louwerse & Mitchell, 2003; McNamara, E. Kintsch, Songer, & W. Kintsch, 1996). For the purpose of clarity, we make a distinction between cohesion and coherence. Specifically, cohesion is a characteristic of the text, whereas coherence is a characteristic of the reader’s mental representation of the text content. Cohesion is an objective property of the explicit language and text. There are explicit features, words, phrases, or sentences that guide the reader in interpreting the substantive ideas in the text, in connecting ideas with other ideas, and in connecting ideas to higher level global units (e.g., topics and themes). These cohesive devices cue the reader on how to form a coherent representation. The coherence relations are constructed in the mind of the reader and depend on the skills and knowledge that the reader brings to the situation. If the reader has adequate world knowledge about the subject matter and if there are adequate linguistic and discourse cues, then the reader is likely to form a coherent mental representation of the text. A reader perceives a text to be coherent to the extent that the ideas conveyed in the text hang together in a meaningful and organized manner. Thus, coherence is an achievement that is a product of psychological representations and processes. Simply put, coherence is a psychological construct, whereas cohesion is a textual construct (Graesser, McNamara, & Louwerse, 2003; Louwerse, 2002; Louwerse & Graesser, in press).Our focus on coherence and cohesion has multiple inspirations in the arena of science. First, the coherence assumption was one of the central theoretical constructs in the constructivist theory of discourse comprehension proposed by Graesser, Singer, and Trabasso (1994). According to this assumption, readers routinely attempt to construct coherent meanings and connections among text constituents unless the text is very poorly composed and they give up trying. Given the significance of the coherence assumption in the theory, it would be important to dissect and possibly automate coherence (and cohesion). Second, McNamara and colleagues have discovered some intriguing interactions between cohesion and world knowledge when students construct and subsequently use mental models underlying science texts (McNamara, 2001; McNamara et al., 1996; McNamara & W. Kintsch, 1996). Readers with less prior knowledge about the science domain are helped by texts with better cohesion, whereas readers with greater science knowledge can benefit from cohesion gaps. Cohesion gaps require the reader to make inferences using either world knowledge or previous textual information. When inferences are generated, the reader makes more connections between ideas in the text and knowledge. This process results in a more coherent mental representation. Hence, cohesion gaps can be beneficial for high-knowledge readers because their knowledge affords successful inference making. These results highlight the importance of pinning down linguistic and discourse features of cohesion and of better understanding the properties of world knowledge. Third, we have had an ongoing interest in directly investigating the processing of conjunctions, connectives, discourse markers, and other classes of linguistic elements that connect constituents in sentences, text, and oral discourse (Graesser, Burger, et al., 2003; Louwerse, 2002; Louwerse & Mitchell, 2003).Our interest in cohesion and coherence also has a practical side. Readability formulas (Klare, 1974–1975) have had a major influence on the textbook industry and on the selection of texts in Grades K–12 and college. Readability formulas have widespread use even though they rely exclusively on word length and sentence length, two very simple and shallow metrics. Readability formulas ignore dozens of language and discourse components that are theoretically expected to influence comprehension diff iculty. Texts are no doubt more difficult to read when they contain longer words and lengthier sentences. Longer words tend to be less frequent in the language, as we know from Zipf ’s (1949) law, and infrequent words take more time to access and interpret during reading (Just & Carpenter, 1980). Longer sentences tend to place more demands on working memory and are therefore more difficult (Graesser, Karnavat, et al., 2001). We do not deny that the wordand sentence-length parameters in these readability formulas have some approximate degree of validity. However, these two-parameter multiple regression equations will not go the distance in explaining text difficulty. Even worse, they will end up being misused. Textbook writers are known to shorten sentences in basal readers for the purpose of downsizing the grade levels of their texts. The unfortunate liability of shortening sentences is that the texts end up having lower cohesion and coherence.These theoretical advances and practical needs have led us to develop a Web-based software tool called Coh-Metrix (for additional information, visit coh-metrix.memphis. edu). Coh-Metrix analyzes texts on over 50 types of cohesion relations and over 200 measures of language, text, and readability. Unlike standard readability formulas, Coh-Metrix is sensitive to a broad profile of language and cohesion characteristics. There are modules that use lexicons, part-ofspeech categorizers, syntactic parsers, templates, corpora, statistical representations of world knowledge, and other components that are widely used in computational linguistics. One important contribution of Coh-Metrix is that all of these modules are located in one central Web facility. Some of these modules incorporate or expand the modules that were developed in a Web facility that analyzes questions on surveys (called Question Understanding Aid, or QUAID; Graesser, K. Wiemer-Hastings, Kreuz, P. Wiemer-Hastings, & Marquis, 2000) and in a computer tutor that helps students learn about subject matter by holding conversations in natural language (called AutoTutor; Graesser, Person, Harter, & the Tutoring Research Group, 2001; Graesser, VanLehn, Rose, Jordan, & Harter, 2001).