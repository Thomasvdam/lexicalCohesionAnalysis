The vision of having a computer understand natural language has persisted for nearly half a century, but it has been challenged by the computational difficulty of simu- lating many of the processing components. The standard wisdom has been that it is particularly more difficult to implement the deeper and more global levels of compre- hension than the shallow and more local levels. The deeper and global levels require semantic interpretation, the con- struction of mental models, text cohesion, pragmatics, rhetorical composition, and world knowledge (Lehnert & Ringle, 1982; Schank & Riesbeck, 1981). The computer is more reliable in managing the more shallow and local components, such as accessing words from electronic dic- tionaries, identifying misspelled words, and splitting up words into component syllables, basic meaning units (mor- phemes), or sound units (phonemes).Recent landmark progress across several disciplines has made it possible to explore computational measures of language and text comprehension that go beyond these surface components. These disciplines include computational linguistics (Allen, 1995; Jurafsky & Martin, 2000; Moore & Wiemer-Hastings, 2003), corpus linguistics (Biber, Conrad, & Reppen, 1998; Marcus, Santorini, & Marcinkiewicz, 1993), information extraction (DARPA, 1995; Lehnert, 1997; Pennebaker & Francis, 1999), infor- mation retrieval (Belew, 2002; Deerwester, Dumais, Fur- nas, Landauer, & Harshman, 1990; Graesser, Burger, et al., 2003; Robertson, 2001; Voorhees, 2001), and dis- course processing (Graesser, Gernsbacher, & Goldman, 2003; Kintsch, 1998). As a consequence of these advances in scientific research and language technologies, we can go some distance in automating many of the deeper and global levels of text and language analysis.One such level of language analysis that presents par- ticular computational challenges is called coherence or co- hesion (Graesser, McNamara, & Louwerse, 2003; Lou- werse & Mitchell, 2003; McNamara, E. Kintsch, Songer, & W. Kintsch, 1996). For the purpose of clarity, we make a distinction between cohesion and coherence. Specifi- cally, cohesion is a characteristic of the text, whereas co- herence is a characteristic of the reader’s mental represen- tation of the text content. Cohesion is an objective property of the explicit language and text. There are explicit fea- tures, words, phrases, or sentences that guide the reader in interpreting the substantive ideas in the text, in connecting ideas with other ideas, and in connecting ideas to higher level global units (e.g., topics and themes). These cohe- sive devices cue the reader on how to form a coherent rep- resentation. The coherence relations are constructed in the mind of the reader and depend on the skills and knowledge that the reader brings to the situation. If the reader has ad- equate world knowledge about the subject matter and if there are adequate linguistic and discourse cues, then the reader is likely to form a coherent mental representation of the text. A reader perceives a text to be coherent to the ex- tent that the ideas conveyed in the text hang together in a meaningful and organized manner. Thus, coherence is an achievement that is a product of psychological representa- tions and processes. Simply put, coherence is a psycho- logical construct, whereas cohesion is a textual construct (Graesser, McNamara, & Louwerse, 2003; Louwerse, 2002; Louwerse & Graesser, in press).Our focus on coherence and cohesion has multiple in- spirations in the arena of science. First, the coherence as- sumption was one of the central theoretical constructs in the constructivist theory of discourse comprehension pro- posed by Graesser, Singer, and Trabasso (1994). Accord- ing to this assumption, readers routinely attempt to con- struct coherent meanings and connections among text constituents unless the text is very poorly composed and they give up trying. Given the significance of the coher- ence assumption in the theory, it would be important to dissect and possibly automate coherence (and cohesion). Second, McNamara and colleagues have discovered some intriguing interactions between cohesion and world knowl- edge when students construct and subsequently use men- tal models underlying science texts (McNamara, 2001; McNamara et al., 1996; McNamara & W. Kintsch, 1996). Readers with less prior knowledge about the science do- main are helped by texts with better cohesion, whereas readers with greater science knowledge can benefit from cohesion gaps. Cohesion gaps require the reader to make inferences using either world knowledge or previous tex- tual information. When inferences are generated, the reader makes more connections between ideas in the text and knowledge. This process results in a more coherent men- tal representation. Hence, cohesion gaps can be beneficial for high-knowledge readers because their knowledge af- fords successful inference making. These results highlight the importance of pinning down linguistic and discourse features of cohesion and of better understanding the prop- erties of world knowledge. Third, we have had an ongoing interest in directly investigating the processing of con- junctions, connectives, discourse markers, and other classes of linguistic elements that connect constituents in sen- tences, text, and oral discourse (Graesser, Burger, et al., 2003; Louwerse, 2002; Louwerse & Mitchell, 2003).Our interest in cohesion and coherence also has a prac- tical side. Readability formulas (Klare, 1974–1975) have had a major influence on the textbook industry and on the selection of texts in Grades K–12 and college. Readabil- ity formulas have widespread use even though they rely exclusively on word length and sentence length, two very simple and shallow metrics. Readability formulas ignore dozens of language and discourse components that are theoretically expected to influence comprehension diff i- culty. Texts are no doubt more difficult to read when they contain longer words and lengthier sentences. Longer words tend to be less frequent in the language, as we know from Zipf ’s (1949) law, and infrequent words take more time to access and interpret during reading (Just & Carpenter, 1980). Longer sentences tend to place more demands on working memory and are therefore more difficult (Graesser, Karnavat, et al., 2001). We do not deny that the word- and sentence-length parameters in these readability formulas have some approximate degree of validity. However, these two-parameter multiple regression equations will not go the distance in explaining text difficulty. Even worse, they will end up being misused. Textbook writers are known to shorten sentences in basal readers for the purpose of downsizing the grade levels of their texts. The unfortunate liability of shortening sentences is that the texts end up having lower cohesion and coherence.These theoretical advances and practical needs have led us to develop a Web-based software tool called Coh-Metrix (for additional information, visit coh-metrix.memphis. edu). Coh-Metrix analyzes texts on over 50 types of cohesion re- lations and over 200 measures of language, text, and read- ability. Unlike standard readability formulas, Coh-Metrix is sensitive to a broad profile of language and cohesion char- acteristics. There are modules that use lexicons, part-of- speech categorizers, syntactic parsers, templates, corpora, statistical representations of world knowledge, and other components that are widely used in computational linguis- tics. One important contribution of Coh-Metrix is that all of these modules are located in one central Web facility. Some of these modules incorporate or expand the modules that were developed in a Web facility that analyzes questions on surveys (called Question Understanding Aid, or QUAID; Graesser, K. Wiemer-Hastings, Kreuz, P. Wiemer-Hastings, & Marquis, 2000) and in a computer tutor that helps stu- dents learn about subject matter by holding conversations in natural language (called AutoTutor; Graesser, Person, Har- ter, & the Tutoring Research Group, 2001; Graesser, Van- Lehn, Rose, Jordan, & Harter, 2001).